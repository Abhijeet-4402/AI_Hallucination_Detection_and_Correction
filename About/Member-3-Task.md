<<<<<<< HEAD
# myTask.md: Correction & Regeneration Engineer (Khushboo)

This document outlines your specific tasks and responsibilities for the AI Hallucination Detection System project. Your primary role is to build the **Correction Module**, which is responsible for fixing hallucinations and ensuring the final output is reliable and trustworthy.

## 📌 Key Objectives

* **Implement Self-Correction:** Build the core logic that regenerates answers from Gemini Pro using factual evidence provided by the retrieval module.
* **Enhance Transparency:** Add confidence scores and source citations to the final output to build user trust.
* **Ensure Accountability:** Log all original and corrected data into an SQLite database for performance tracking and analysis.

## 🛠️ Your Technology Stack

You will be using the following technologies to complete your tasks:
* **Python**
* **LangChain** (specifically the `RetrievalQA` chain)
* **SQLite3**
* **sentence-transformers**

---

## ✅ Task Checklist

Here is a step-by-step breakdown of your tasks.

### 1. Database Setup
* [ ] **Initialize SQLite Database:** Create the SQLite database file (`hallucination_log.db`).
* [ ] **Create Logs Table:** Using Python's `sqlite3` module, create a table to store the results of the pipeline.
* [cite_start][ ] **Implement Schema:** The table must have the following schema as specified in the project plan: `(Question, RawAnswer, CorrectedAnswer, Citations, ConfidenceScore)`[cite: 42]. You should also include an auto-incrementing ID and a timestamp for good practice.

### 2. Core Correction Logic
* [cite_start][ ] **Define Main Function:** Create the primary function for your module, as outlined in the integration guide, that will take the raw answer and retrieved evidence as input[cite: 11].
* [cite_start][ ] **Implement RAG:** Use the LangChain `RetrievalQA` chain to regenerate the answer[cite: 41]. [cite_start]This involves passing the retrieved evidence (from Shubh's module) to Gemini Pro to generate a new, fact-grounded response[cite: 11].
* [ ] **Extract Source Information:** Ensure your `RetrievalQA` chain is configured to `return_source_documents` so you can access them for citations later.

### 3. Output Enhancement
* [ ] **Calculate Confidence Score:** Implement a function to calculate a confidence score. [cite_start]This should be a "similarity measure" comparing the semantic meaning of your corrected answer against the source evidence documents using `sentence-transformers`[cite: 40].
* [ ] **Add Citations:** From the source documents returned by your RAG chain, extract the source (e.g., Wikipedia) and format it as a citation to be appended to or delivered with the final answer.

### 4. Logging
* [ ] **Database Connection:** Write the code to connect to your SQLite database within your main function.
* [cite_start][ ] **Store All Results:** After generating the corrected answer and confidence score, save the complete record into the database: the original question, Gemini's raw answer, your corrected answer, the citations, and the confidence score[cite: 40].

### 5. Testing
* [cite_start][ ] **Unit Testing:** Test your correction function with a small, sample set of questions from the TruthfulQA dataset to verify functionality[cite: 42].

---

## 🤝 Integration Points

Your module is a critical link in the project pipeline.

* **Your Inputs (Dependencies):**
    * You will need the `raw_answer` generated by **Abhijeet's (LLM & Detection Engineer)** module.
    * [cite_start]You will need the `evidence` (retrieved documents from ChromaDB/Wikipedia) from **Shubh's (Data & Retrieval Engineer)** module[cite: 11].
* **Your Outputs (Deliverables):**
    * [cite_start]You will provide a dictionary containing the `CorrectedAnswer`, `Citations`, and `ConfidenceScore` to **Harshita's (Frontend & UX Engineer)** module, which will display it to the user via the Flask API and Streamlit UI[cite: 13, 20].

## 🏁 Acceptance Criteria

Your module is considered complete when:
1.  You have a Python script that can be imported into the main application.
2.  The script provides a primary function that successfully regenerates a fact-based answer from a raw answer and evidence documents.
3.  The function's output is a structured object (e.g., a dictionary) containing the corrected answer, citations, and a confidence score.
4.  For every run, a new row is successfully inserted into the SQLite `logs` table with all the required data.
=======
# myTask.md: Correction & Regeneration Engineer (Khushboo)

This document outlines your specific tasks and responsibilities for the AI Hallucination Detection System project. Your primary role is to build the **Correction Module**, which is responsible for fixing hallucinations and ensuring the final output is reliable and trustworthy.

## 📌 Key Objectives

* **Implement Self-Correction:** Build the core logic that regenerates answers from Gemini Pro using factual evidence provided by the retrieval module.
* **Enhance Transparency:** Add confidence scores and source citations to the final output to build user trust.
* **Ensure Accountability:** Log all original and corrected data into an SQLite database for performance tracking and analysis.

## 🛠️ Your Technology Stack

You will be using the following technologies to complete your tasks:
* **Python**
* **LangChain** (specifically the `RetrievalQA` chain)
* **SQLite3**
* **sentence-transformers**

---

## ✅ Task Checklist

Here is a step-by-step breakdown of your tasks.

### 1. Database Setup
* [ ] **Initialize SQLite Database:** Create the SQLite database file (`hallucination_log.db`).
* [ ] **Create Logs Table:** Using Python's `sqlite3` module, create a table to store the results of the pipeline.
* [cite_start][ ] **Implement Schema:** The table must have the following schema as specified in the project plan: `(Question, RawAnswer, CorrectedAnswer, Citations, ConfidenceScore)`[cite: 42]. You should also include an auto-incrementing ID and a timestamp for good practice.

### 2. Core Correction Logic
* [cite_start][ ] **Define Main Function:** Create the primary function for your module, as outlined in the integration guide, that will take the raw answer and retrieved evidence as input[cite: 11].
* [cite_start][ ] **Implement RAG:** Use the LangChain `RetrievalQA` chain to regenerate the answer[cite: 41]. [cite_start]This involves passing the retrieved evidence (from Shubh's module) to Gemini Pro to generate a new, fact-grounded response[cite: 11].
* [ ] **Extract Source Information:** Ensure your `RetrievalQA` chain is configured to `return_source_documents` so you can access them for citations later.

### 3. Output Enhancement
* [ ] **Calculate Confidence Score:** Implement a function to calculate a confidence score. [cite_start]This should be a "similarity measure" comparing the semantic meaning of your corrected answer against the source evidence documents using `sentence-transformers`[cite: 40].
* [ ] **Add Citations:** From the source documents returned by your RAG chain, extract the source (e.g., Wikipedia) and format it as a citation to be appended to or delivered with the final answer.

### 4. Logging
* [ ] **Database Connection:** Write the code to connect to your SQLite database within your main function.
* [cite_start][ ] **Store All Results:** After generating the corrected answer and confidence score, save the complete record into the database: the original question, Gemini's raw answer, your corrected answer, the citations, and the confidence score[cite: 40].

### 5. Testing
* [cite_start][ ] **Unit Testing:** Test your correction function with a small, sample set of questions from the TruthfulQA dataset to verify functionality[cite: 42].

---

## 🤝 Integration Points

Your module is a critical link in the project pipeline.

* **Your Inputs (Dependencies):**
    * You will need the `raw_answer` generated by **Abhijeet's (LLM & Detection Engineer)** module.
    * [cite_start]You will need the `evidence` (retrieved documents from ChromaDB/Wikipedia) from **Shubh's (Data & Retrieval Engineer)** module[cite: 11].
* **Your Outputs (Deliverables):**
    * [cite_start]You will provide a dictionary containing the `CorrectedAnswer`, `Citations`, and `ConfidenceScore` to **Harshita's (Frontend & UX Engineer)** module, which will display it to the user via the Flask API and Streamlit UI[cite: 13, 20].

## 🏁 Acceptance Criteria

Your module is considered complete when:
1.  You have a Python script that can be imported into the main application.
2.  The script provides a primary function that successfully regenerates a fact-based answer from a raw answer and evidence documents.
3.  The function's output is a structured object (e.g., a dictionary) containing the corrected answer, citations, and a confidence score.
4.  For every run, a new row is successfully inserted into the SQLite `logs` table with all the required data.
>>>>>>> fb3451155c14f135a09046a366815aba1850f393
5.  The code is ready to be integrated into the main Flask backend pipeline.